{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k-Means - Vanilla and Mini-Batch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFXiLxoBOL5G"
      },
      "source": [
        "import keras\n",
        "\n",
        "#importing MNIST data of 60000 examples and 784 features\n",
        "(X_train, y_train), (X_test, y_test)=keras.datasets.mnist.load_data(path=\"/content/mnist.npz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Tt14eEPFb4"
      },
      "source": [
        "## Observations\n",
        "\n",
        "- Importing MNIST dataset from keras datasets library into separate train and test variables for both features and labels.\n",
        "- np.average method can be used to take averages of elements from different lists. \n",
        "- \n",
        "Experimental result:\n",
        "=================================Implemented Function==========================================\n",
        "Points in cluster 1: 8798\n",
        "Points in cluster 2: 4616\n",
        "Points in cluster 3: 4704\n",
        "Points in cluster 4: 4176\n",
        "Points in cluster 5: 5764\n",
        "Points in cluster 6: 3015\n",
        "Points in cluster 7: 5837\n",
        "Points in cluster 8: 9973\n",
        "Points in cluster 9: 4348\n",
        "Points in cluster 10: 8769\n",
        "=================================Library Function==========================================\n",
        "4    7574\n",
        "5    7232\n",
        "8    7229\n",
        "6    6895\n",
        "9    5885\n",
        "2    5465\n",
        "1    5390\n",
        "7    4946\n",
        "3    4704\n",
        "0    4680\n",
        "dtype: int64\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhcUYLto59nc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (60000, 784))\n",
        "X_test = np.reshape(X_test, (10000, 784))\n",
        "X_train = X_train.astype('float64')\n",
        "X_test = X_test.astype('float64')\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz5j0u2x3uUm"
      },
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# X_train = np.reshape(X_train, (60000, 784))\n",
        "# X_train = pd.DataFrame(X_train)\n",
        "# print(X_train.iloc[0].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zt7I5V9h0JL"
      },
      "source": [
        "# !pip install cython\n",
        "# %load_ext Cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjV92W9J9ztH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import keras\n",
        "\n",
        "#importing MNIST data of 60000 examples and 784 features\n",
        "(X_train, y_train), (X_test, y_test)=keras.datasets.mnist.load_data(path=\"/content/mnist.npz\")\n",
        "\n",
        "X_train = np.reshape(X_train, (60000, 784))\n",
        "X_test = np.reshape(X_test, (10000, 784))\n",
        "X_train = X_train.astype('float64')\n",
        "X_test = X_test.astype('float64')\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "\n",
        "def MiniBatchKmeans(k: int, b: int, t: int, X: np.ndarray, random_state = None):\n",
        "\n",
        "    shape_x = X.shape[0]    #shape of X along x-axis\n",
        "    shape_y = X.shape[1]    #shape of X along y-axis\n",
        "\n",
        "    #initializing centroids\n",
        "    centroids = np.empty((0,shape_y))   #initially empty\n",
        "    np.random.seed(random_state)    #seed random function with random state of the user\n",
        "    x = np.random.choice(shape_x, size=k, replace=False)    #choose k numbers from [0,k) for indexing\n",
        "    centroids = np.append(centroids, np.array(X[x]), axis=0)    #append chosen examples into centroids\n",
        "    \n",
        "    #count for each cluster\n",
        "    v = np.zeros(k, dtype=int)\n",
        "\n",
        "    #loop for max_iter iterations\n",
        "    itr = 0\n",
        "    flag = True\n",
        "    while flag and itr < max_iter:\n",
        "        flag = False\n",
        "        chosen_indices = np.random.choice(shape_x, size = b, replace=False) #choose shape_x \n",
        "        M = X[chosen_indices]        #sample batch\n",
        "        d = np.array([])    #distance matrix\n",
        "        for i in range(k):\n",
        "            sub = M - centroids[i]     #matrix - vector = all rows subtracted from matrix with corresponding vector values\n",
        "            d = np.append(d, np.linalg.norm(sub, axis=1), axis=0)   #filling distance matrix\n",
        "        itr += 1\n",
        "        d=d.reshape((k, M.shape[0]))  #reshape d to (k, shape_x)\n",
        "        for idx, x in enumerate(M):\n",
        "            x_d = d[:,idx]\n",
        "            c = np.where(x_d == min(x_d))[0][0]\n",
        "            v[c] = v[c] + 1\n",
        "            count = float(v[c])\n",
        "            newc = np.array(((count - 1) * centroids[c] + x)/count)\n",
        "            if not np.array_equal(newc, centroids[c]):\n",
        "                centroids[c] = newc\n",
        "                flag = True\n",
        "    return centroids\n",
        "\n",
        "k=10\n",
        "b = 100\n",
        "max_iter = 300\n",
        "mbk = MiniBatchKmeans(k, b, max_iter, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FKzgqGBtg-r"
      },
      "source": [
        "l1 = np.array([1,2,3])\n",
        "l2 = np.array([1,2,3])\n",
        "if np.array_equal(l1, l2):\n",
        "    print(True)\n",
        "else:\n",
        "    print(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrMSeXyWsPLf"
      },
      "source": [
        "%run -d -b27 minibatchkmeans.py "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaPBAkYpSMNh"
      },
      "source": [
        "# a = np.array([[3, 1, 4],\n",
        "#               [3, 2, 2],\n",
        "#               [5, 3, 6],\n",
        "#               [0,0,1]])\n",
        "# # a = a/6\n",
        "# min_a = np.amin(a, axis = 0)\n",
        "# idxs = np.where(a == min_a)  # -1 is broadcast\n",
        "# idxs = np.array(idxs)\n",
        "# print(idxs[1])\n",
        "# _, idx = np.unique(idxs[1], return_index=True)\n",
        "# min_d = idxs[:,idx][0]\n",
        "# # print(idxs)\n",
        "# # print(np.unique(idxs[1]))\n",
        "# c_idx = np.array(idxs[np.unique(idxs[:,1])])\n",
        "# c_idx.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFS1oSMjirSD"
      },
      "source": [
        "# k = 10\n",
        "# clusters = {}\n",
        "# for i in range(k):\n",
        "#     cluster[i] = np.array([])\n",
        "\n",
        "# l = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "509m46l6QCDX"
      },
      "source": [
        "#k-means \n",
        "import numpy as np\n",
        "from scipy import sparse as sp\n",
        "import pandas as pd\n",
        "\n",
        "def allocate_clusters(X: pd.DataFrame, centroids: list, k: int):\n",
        "  '''\n",
        "  Reconstruct the clusters\n",
        "  '''\n",
        "  #reinitializing clusters\n",
        "  clusters= {}\n",
        "  for i in range(1,k+1):\n",
        "    clusters[i] = []\n",
        "\n",
        "  for i in range(X.shape[0]):\n",
        "    x = X.loc[i]  #for every example x\n",
        "    euc_dist = []  \n",
        "    for j in range(1,k+1):\n",
        "        euc_dist.append(np.linalg.norm(x - centroids[j]))  #find distances to all centroids from x\n",
        "    clusters[euc_dist.index(min(euc_dist))+1].append([x])  #add x to the closest cluster\n",
        "  return clusters\n",
        "\n",
        "def update_centroids(X: pd.DataFrame, centroids: list, clusters: dict, k: int):\n",
        "  '''\n",
        "  Update centroid values by taking average \n",
        "  '''\n",
        "  for i in range(1,k+1):\n",
        "      centroids[i] = np.average(clusters[i], axis=0)[0] #find average for each feature\n",
        "  return centroids\n",
        "\n",
        "\n",
        "def Kmeans(X: pd.DataFrame, k: int, max_iter: int = 300, random_state: int = None):\n",
        "  '''\n",
        "  Implementation of K-Means clustering algorithm\n",
        "  params:\n",
        "  X: Sample Data\n",
        "  k: Number of clusters\n",
        "  max_iter (optional): Maximum number of iterations; default = 300\n",
        "  random_state (optional): int or RandomState instance; default = None\n",
        "  '''\n",
        "  #validating if DataFrame\n",
        "  if not isinstance(X, pd.DataFrame):\n",
        "    X = pd.DataFrame(X)\n",
        "\n",
        "  #centering data for ease in distance computations\n",
        "  if not sp.issparse(X):\n",
        "            X_mean = X.mean(axis=0)\n",
        "            # The copy was already done above\n",
        "            X -= X_mean\n",
        "  \n",
        "  #initalizing centroids\n",
        "  np.random.seed(random_state)\n",
        "  centroids = [0]\n",
        "  for i in range(1,k+1):\n",
        "    x = np.random.randint(0,X.shape[0]-1)\n",
        "    centroids.append(X.loc[x])\n",
        "\n",
        "  #initializing clusters\n",
        "  clusters= {}\n",
        "  for i in range(1,k+1):\n",
        "    clusters[i] = []\n",
        "\n",
        "  #Step 1: Allocate examples to the closest clusters\n",
        "  clusters = allocate_clusters(X, centroids, k)\n",
        "\n",
        "  #loop until convergence\n",
        "  flag = True   #flag to check convergence\n",
        "  iter = 0\n",
        "  while iter < max_iter and flag:\n",
        "      flag = False #flag to check convergence\n",
        "\n",
        "      #Step 1: Allocate examples to the closest clusters\n",
        "      clusters = allocate_clusters(X, centroids, k)\n",
        "\n",
        "      #Step 2: Update centroid values\n",
        "      updated_centroids = update_centroids(X, centroids, clusters, k)\n",
        "      \n",
        "      #check for convergence\n",
        "      if not update_centroids == centroids:\n",
        "          flag = True\n",
        "\n",
        "      centroids = updated_centroids   #updated centroids\n",
        "\n",
        "      iter += 1   #increment iteration count\n",
        "      \n",
        "  #print output\n",
        "  for i in range(1,k+1):\n",
        "    print(f'Points in cluster {i}: {len(clusters[i])}')\n",
        "  return centroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POCisRrE0r-q"
      },
      "source": [
        "# #initializing clusters\n",
        "# clusters= {}\n",
        "# for i in range(k):\n",
        "#     clusters[i] = []\n",
        "\n",
        "\n",
        "# for i in range(k):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IutYbgR43n6Z"
      },
      "source": [
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "\n",
        "\n",
        "b = 100\n",
        "max_iter = 1000\n",
        "for k in range(1,10):\n",
        "    mbki = MiniBatchKmeans(k, b, max_iter, X_train)\n",
        "\n",
        "    labelsi = pairwise_distances_argmin(X_train, mbki)\n",
        "    print(pd.Series(labelsi).value_counts())\n",
        "\n",
        "for k in range(10, 1000, 10):\n",
        "    mbki = MiniBatchKmeans(k, b, max_iter, X_train)\n",
        "\n",
        "    labelsi = pairwise_distances_argmin(X_train, mbki)\n",
        "    print(pd.Series(labelsi).value_counts())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0rJLVH06_Kg"
      },
      "source": [
        "# 9    9546\n",
        "# 2    8711\n",
        "# 6    6520\n",
        "# 5    5986\n",
        "# 1    5970\n",
        "# 3    5689\n",
        "# 4    5267\n",
        "# 0    4746\n",
        "# 8    4041\n",
        "# 7    3524\n",
        "# dtype: int64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie3lAOqd4WPf"
      },
      "source": [
        "# print(__doc__)\n",
        "\n",
        "# import time\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.cluster import MiniBatchKMeans, KMeans\n",
        "# from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "# from sklearn.datasets import make_blobs\n",
        "\n",
        "# # #############################################################################\n",
        "# # Generate sample data\n",
        "# np.random.seed(0)\n",
        "\n",
        "# batch_size = 45\n",
        "# centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "# n_clusters = len(centers)\n",
        "# X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n",
        "\n",
        "# # #############################################################################\n",
        "# # Compute clustering with Means\n",
        "\n",
        "# k_means = KMeans(init='k-means++', n_clusters=3, n_init=10)\n",
        "# t0 = time.time()\n",
        "# k_means.fit(X)\n",
        "# t_batch = time.time() - t0\n",
        "\n",
        "# # #############################################################################\n",
        "# # Compute clustering with MiniBatchKMeans\n",
        "\n",
        "# mbk = MiniBatchKMeans(init='k-means++', n_clusters=3, batch_size=batch_size,\n",
        "#                       n_init=10, max_no_improvement=10, verbose=0)\n",
        "# t0 = time.time()\n",
        "# mbk.fit(X)\n",
        "# t_mini_batch = time.time() - t0\n",
        "\n",
        "# # #############################################################################\n",
        "# # Plot result\n",
        "\n",
        "# fig = plt.figure(figsize=(8, 3))\n",
        "# fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
        "# colors = ['#4EACC5', '#FF9C34', '#4E9A06']\n",
        "\n",
        "# # We want to have the same colors for the same cluster from the\n",
        "# # MiniBatchKMeans and the KMeans algorithm. Let's pair the cluster centers per\n",
        "# # closest one.\n",
        "# k_means_cluster_centers = k_means.cluster_centers_\n",
        "# order = pairwise_distances_argmin(k_means.cluster_centers_,\n",
        "#                                   mbk.cluster_centers_)\n",
        "# mbk_means_cluster_centers = mbk.cluster_centers_[order]\n",
        "# print(k_means_cluster_centers)\n",
        "# k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)\n",
        "# mbk_means_labels = pairwise_distances_argmin(X, mbk_means_cluster_centers)\n",
        "# print(k_means_labels)\n",
        "# # KMeans\n",
        "# ax = fig.add_subplot(1, 3, 1)\n",
        "# for k, col in zip(range(n_clusters), colors):\n",
        "#     my_members = k_means_labels == k\n",
        "#     cluster_center = k_means_cluster_centers[k]\n",
        "#     ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n",
        "#             markerfacecolor=col, marker='.')\n",
        "#     ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
        "#             markeredgecolor='k', markersize=6)\n",
        "# ax.set_title('KMeans')\n",
        "# ax.set_xticks(())\n",
        "# ax.set_yticks(())\n",
        "# plt.text(-3.5, 1.8,  'train time: %.2fs\\ninertia: %f' % (\n",
        "#     t_batch, k_means.inertia_))\n",
        "\n",
        "# # MiniBatchKMeans\n",
        "# ax = fig.add_subplot(1, 3, 2)\n",
        "# for k, col in zip(range(n_clusters), colors):\n",
        "#     my_members = mbk_means_labels == k\n",
        "#     cluster_center = mbk_means_cluster_centers[k]\n",
        "#     ax.plot(X[my_members, 0], X[my_members, 1], 'w',\n",
        "#             markerfacecolor=col, marker='.')\n",
        "#     ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
        "#             markeredgecolor='k', markersize=6)\n",
        "# ax.set_title('MiniBatchKMeans')\n",
        "# ax.set_xticks(())\n",
        "# ax.set_yticks(())\n",
        "# plt.text(-3.5, 1.8, 'train time: %.2fs\\ninertia: %f' %\n",
        "#          (t_mini_batch, mbk.inertia_))\n",
        "\n",
        "# # Initialise the different array to all False\n",
        "# different = (mbk_means_labels == 4)\n",
        "# ax = fig.add_subplot(1, 3, 3)\n",
        "\n",
        "# for k in range(n_clusters):\n",
        "#     different += ((k_means_labels == k) != (mbk_means_labels == k))\n",
        "\n",
        "# identic = np.logical_not(different)\n",
        "# ax.plot(X[identic, 0], X[identic, 1], 'w',\n",
        "#         markerfacecolor='#bbbbbb', marker='.')\n",
        "# ax.plot(X[different, 0], X[different, 1], 'w',\n",
        "#         markerfacecolor='m', marker='.')\n",
        "# ax.set_title('Difference')\n",
        "# ax.set_xticks(())\n",
        "# ax.set_yticks(())\n",
        "\n",
        "# # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf9Tqk3fchf5"
      },
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv8e-PPKfghH"
      },
      "source": [
        "# # reading the data and looking at the first five rows of the data\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# data_scaled = scaler.fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3_aufr0nbnbc"
      },
      "source": [
        "\n",
        "print('=================================Implemented Function==========================================')\n",
        "centroids = Kmeans(X_train, 10, 15, random_state=42)\n",
        "\n",
        "# # k means using 10 clusters initialization\n",
        "kmeans = KMeans(n_clusters = 10, max_iter = 15, random_state=42)\n",
        "\n",
        "kmeans.fit(X_train)\n",
        "pred = kmeans.labels_\n",
        "print('=================================Library Function==========================================')\n",
        "print(pd.Series(pred).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCHHnj69baY7"
      },
      "source": [
        "print(pd.Series(y_train).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vwet8HNen2y"
      },
      "source": [
        "# cluster = [-0.65607391, 0.50791595,  0.14838137, -0.49656661, -0.56620088, -0.25608672, -0.50849408, -0.3223056 ]\n",
        "# average = np.average(cluster, axis=0)\n",
        "# if not np.abs(average - cluster).any():\n",
        "#   flag = True\n",
        "# cluster = average\n",
        "# print(flag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLrRy7iLHn7x"
      },
      "source": [
        "# def bar():\n",
        "#   x = 0\n",
        "#   foo()\n",
        "# def foo():\n",
        "#   print(x)\n",
        "\n",
        "# bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLJwPyZaRlp0"
      },
      "source": [
        "'''\n",
        "References:\n",
        "  Gaurav Sir's Notes and Lectures\n",
        "  https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/\n",
        "  https://docs.python.org/3/library/random.html\n",
        "  https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions\n",
        "  https://www.geeksforgeeks.org/calculate-the-euclidean-distance-using-numpy/\n",
        "  https://www.geeksforgeeks.org/python-maximum-minimum-elements-position-list/\n",
        "  https://towardsdatascience.com/k-means-without-libraries-python-feb3572e2eef\n",
        "  https://stackoverflow.com/questions/14808945/check-if-variable-is-dataframe\n",
        "  https://stackoverflow.com/questions/14808945/check-if-variable-is-dataframe\n",
        "  https://blog.finxter.com/compare-two-lists-in-python/#:~:text=Short%20answer%3A%20The%20most%20Pythonic,the%20return%20value%20is%20True%20.\n",
        "  https://www.geeksforgeeks.org/random-seed-in-python/\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "  https://stackoverflow.com/questions/58842373/typeerror-int-object-is-not-callable-in-np-random-seed\n",
        "  https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/cluster/_kmeans.py#L749\n",
        "  https://numpy.org/doc/stable/reference/generated/numpy.append.html\n",
        "  https://www.geeksforgeeks.org/how-to-randomly-select-rows-from-pandas-dataframe/\n",
        "  https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
        "  https://stackoverflow.com/questions/26333005/numpy-subtract-every-row-of-matrix-by-vector/26333184\n",
        "  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html\n",
        "  https://numpy.org/doc/stable/reference/generated/numpy.divide.html\n",
        "  https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.06-Errors-and-Debugging.ipynb#scrollTo=xqgyKJQbqNOy\n",
        "  https://numpy.org/doc/stable/reference/random/generated/numpy.random.shuffle.html\n",
        "  https://stackoverflow.com/questions/6980749/simpler-way-to-put-pdb-breakpoints-in-python-code\n",
        "  https://stackoverflow.com/questions/23911875/select-certain-rows-condition-met-but-only-some-columns-in-python-numpy\n",
        "  https://scikit-learn.org/stable/auto_examples/cluster/plot_mini_batch_kmeans.html#sphx-glr-auto-examples-cluster-plot-mini-batch-kmeans-py\n",
        "  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances_argmin.html#sklearn.metrics.pairwise_distances_argmin\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3rKKmXringx"
      },
      "source": [
        "'''\n",
        "Why algo is so slow?\n",
        " https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
        "Use of MiniBatchKMeans to reduce computations: https://medium.com/datadriveninvestor/k-means-clustering-for-imagery-analysis-56c9976f16b6\n",
        "Streaming average: https://blog.superfeedr.com/streaming-average/\n",
        "Algo for MiniBatchKmeans : https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf\n",
        "Difference between lists and numpy array: https://www.geeksforgeeks.org/python-lists-vs-numpy-arrays/\n",
        "Taking min across columns of numpy array: https://thispointer.com/numpy-amin-find-minimum-value-in-numpy-array-and-its-index/\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}